% ---
\documentclass{article}


\usepackage[USenglish]{babel} 	% Change hyphenation rules
\usepackage{hyperref} 				% Add a link to your document
\usepackage{graphicx}				% Add pictures to your document
\graphicspath{ {./images/} }	% image directory
\usepackage{listings} 				% Source code formatting and highlighting
\lstset{basicstyle=\ttfamily}		%Typewriter font for code writing
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{enumitem}
\usepackage{float}
%\floatstyle{boxed}
\restylefloat{figure}
\usepackage{mathabx}
\usepackage{fancyhdr}
\usepackage{mdframed}
\usepackage{needspace}
\usepackage[dvipsnames]{xcolor}
\usepackage{scrextend}

% Colors
\definecolor{blu}{rgb}{0,0,1}
\def\blu#1{{\color{blu}#1}}
\definecolor{gre}{rgb}{0,.5,0}
\def\gre#1{{\color{gre}#1}}
\definecolor{red}{rgb}{1,0,0}
\def\red#1{{\color{red}#1}}
\def\norm#1{\|#1\|}

\pagestyle{fancy}
\fancyhf{}
\lhead{\bf CPSC 340 \\ Week 5 }
\rhead{\bf Jeremi Do Dinh \\ 61985628}
\rfoot{Page \thepage}



\usepackage{tikz}						% Graph drawing tools
\usetikzlibrary {positioning}

\usepackage{breqn}
\usepackage{multicol} 				% Multiple column functionality
\usepackage{blindtext}
\newcommand{\centerfig}[2]{\begin{center}\includegraphics[width=#1\textwidth]{#2}\end{center}}

\newmdenv[
topline=false,
bottomline=false,
skipabove=\topsep,
skipbelow=\topsep
]{siderules}

\begin{document}
\section*{Lecture 13: Local Search}
\textbf{February 4th, 2020} \\
\url{https://www.cs.ubc.ca/~jordon/teaching/cpsc322/2019w2/lectures/lecture13.pdf}
\subsection*{Local Search}
\begin{siderules}
\subsubsection*{Motivation: Scale}
Many CSPs (scheduling, DNA computing, etc.) are simply too big for systematic approaches. If we have $ 10^5 $ variables, each with a domain size of $ 10^4 $, then systematic search will have a complexity of $ O(b^m) = (10^4)^{(10^5)} $ and arc consistency will have a complexity of $ O(n^2d^3) = (10^{10}) \times (10^{12}) $. But if the solutions are densely distributed, then we can apply local search. 

\end{siderules}


\subsubsection*{General method for Local search}
For this we need to remember that the solution to a CSP is a possible world, and \red{not a path}. Thus we follow the following general stages:
\begin{itemize}
	\item Start from a possible world
	\item Generate some neighbors ( “similar” possible worlds)
	\item Move from the current node to a neighbor, selected according to a particular strategy
\end{itemize}


\subsubsection*{Selecting Neighbors}
Usually this is simple: some small incremental change to the variable assignment. 

\begin{enumerate}[label =(\alph*) ]
	\item assignments that differ in one variable's value, by (for instance) a value difference of $ +1 $
	\item assignments that differ (by any amount) in one variable's value
	\item assignments that differ in two variables' values, etc.
\end{enumerate}

\subsubsection*{Iterative Best improvement}
In order to determine the neighbor node to be selected, we use the method of \textbf{\blu{Iterative Best Improvement}}, which chooses neighbors that optimized some evaluation function. \\ \\
In any case, the best strategy would be to choose the neighbor which has the minimal number of constraint violations. 

\begin{siderules}
	
	\subsubsection*{Example: N-queen as a local search problem}
	The formulation is as follows:
	\begin{itemize}
		\item We have One variable per column, and the domains are $ \{1,...,N\} $ corresponding to row where the queen in the $ i^{th} $ column sits.
		\item Constraints: no two queens in the same row, column or diagonal
	\end{itemize}
The \red{Neighbor relation} is that the value of a single column differs. \\
The \red{Scoring function} is the number of possible attacks \\ \\
The algorithm therefore goes:
\begin{lstlisting}[tabsize=3]
	For each column:
		assign randomly each queen to a row (a number between 1 and N)
		
	While not solved:
	
		For each column & each number: 
			Evaluate how many constraint violations changing the \
				 	assignment would yield
		end for
		
		Choose the column and number that leads to the fewest \
				violated constraints; 
		change the assignment
	end While
\end{lstlisting}
\textbf{Why this problem?} \\ \\
Lots of research in the 90’s on local search for CSP was generated by the observation that the run-time of local search on n-queens problems is essentially independent of problem size!
	\centerfig{1}{n-queens}
	\end{siderules}



\subsection*{Constrained Optimization}
So far we have assumed that we just want to find a possible world that satisfies all the constraints, but sometimes solutions may have different values/costs... \\\\
We want to find the optimal solution that
\begin{itemize}
	\item \textbf{maximizes the value} \textit{or}
	\item \textbf{minimizes the cost}
\end{itemize}
Two options:
\begin{enumerate}
	\item \blu{\textbf{Hill Climbing}} means selecting the neighbor which best improves a (value-based) scoring function.
	\item \blu{\textbf{Greedy Descent}} means selecting the neighbor which minimizes a (cost-based) scoring function.
\end{enumerate}

\subsection*{Hill-climbing}
\textit{\textbf{NOTE}: Everything that will be said for Hill Climbing is also true for Greedy Descent}
\centerfig{0.7}{hill-climbing}

\begin{siderules}
	Example: $ A,B,C  $ same domain $ \{1,2,3\} $ , $ (A=B, A>1, C \ne 3) $
	\begin{itemize}
		\item Value = $ (C+A) $ so we want a solution that maximizes that
		\item The scoring function we’d like to maximize might be: $ f(n) = (C + A) + $ number-of-satisfied-const
	\end{itemize}
If we’re doing Greedy Descent, then what we want to minimize is $ cost + number-of-conflicts $

	\end{siderules}

\subsection*{Problems with Greedy Descent/Hill Climbing}
The main problems with those methods are local maxima, plateaus and shoulders. Those are shown in the figure below:
\centerfig{0.8}{problems-1}

There are also other problems associated with these methods, notably in higher dimensions. Those involve:
\begin{itemize}
	\item Ridges – sequence of local maxima not directly connected to each other
	\item From each local maximum you can only go downhill
\end{itemize}
\centerfig{0.8}{problems-2}

An example of this in the n-queens problem is the following state:
\centerfig{0.4}{problems-3}
In the state above we currently have a local minimum with $ h = 1 $, however each neighboring state will have $ h > 1 $
\newpage

\section*{Lecture 14}
\textbf{February 4\&6th, 2020} \\
\url{https://www.cs.ubc.ca/~jordon/teaching/cpsc322/2019w2/lectures/lecture14.pdf}

\subsection*{Stochastic Local Search}
\textbf{Goal:} We want our local search
\begin{itemize}
	\item To be guided by the scoring function
	\item Not to get stuck in local maxima/minima, plateaus etc.
\end{itemize} 
\textbf{Solution:} We can alternate
\begin{enumerate} [label = (\alph*)]
	\item Hill-climbing steps
	\item Random steps: move to a random neighbor.
	\item Random restart: reassign random values to all variables.
\end{enumerate}
Using the following two graphs as examples, we have that random restarts would work best for example $ X $ and random steps would work best on example $ Y $:
\centerfig{1}{random-steps}
But these examples are simplified extreme cases for illustration. In practice, you don’t know what your search space looks like, thus we usually integrate both kinds of randomization, and see that this works best.

\subsubsection*{Random Steps (Walk): one-step}
Let’s assume that neighbors are generated as assignments that differ in one variable's value. Then given $ n $ variables with domains of size $ d $, a state will have $ n(d-1) $ neighbors. \\ \\
One strategy to add randomness to the selection of the variable-value pair. Thus we sometimes  choose the pair:
\begin{enumerate}
	\item According to the scoring function 
	\item A random one
\end{enumerate}
For the $ n $-queens problem, this would translate to:
\begin{enumerate}
	\item Choose one of the best neighbors 
	\item Choose a random neighbor
\end{enumerate}
\subsubsection*{Random Steps (Walk): two-step}
Another strategy: select a variable first, then a value:
\begin{itemize}
	\item Sometimes select variable:
	\begin{enumerate}
		\item that participates in the largest number of conflicts.
	\item at random, any variable that participates in some conflict
	\item at random
	\end{enumerate}
	\item Sometimes choose value
	\begin{enumerate}[label = \alph*)]
		\item That minimizes number of conflicts 
		\item at random
	\end{enumerate}
\end{itemize}

\subsection*{Stochastic Local search (SLS) advantages}

\subsubsection*{Online setting}
For instance we find SLS very useful in situation where the problem can change (particularly important in scheduling). For instance in the case of airline scheduling: thousands of flights and thousands of personnel assignments, and a storm can render the schedule infeasible... \\ \\
The \textbf{goal} is to \blu{repair} with minimum number of changes:
\begin{itemize}
	\item This can be easily done with a local search starting form the current schedule
	\item Othertechniquesusually:
	\begin{itemize}
		\item require more time
		\item might find solution requiring many more changes
	\end{itemize}
\end{itemize}

\subsubsection*{Anytime algorithms}
When should the algorithm be stopped?
\begin{itemize}
	\item When a solution is found (e.g. no constraint violations)
	\item Or when we are out of time: you have to act NOW
	\item Anytime algorithm:
	\begin{itemize}
		\item maintain the node with best $ h $ found so far (the “incumbent”) 
		\item given more time, can improve its incumbent
	\end{itemize}
\end{itemize}


\subsection*{Stochastic Local search (SLS) limitations}
Typically there is no guarantee that a solution will be found even if one exists. This is because SLS algorithms can sometimes \red{\textbf{stagnate}} (get caught in one region of the search space and never terminate). This is very hard to analyze theoretically. \\ \\
Sometimes we are not able to show that no solution exists, because SLS simply won’t terminate. This means that either:
\begin{enumerate}
	\item You don’t know whether the problem is infeasible 
	\item The algorithm has stagnated
\end{enumerate}

\subsection*{Evaluating SLS algorithms}
SLS algorithms are randomized, meaning that the time taken until they solve a problem is a \red{random variable}. It is entirely normal to have runtime variations of 2 orders of magnitude in repeated runs:
\begin{itemize}
	\item E.g. 0.1 seconds in one run, 10 seconds in the next one
	\item On the same problem instance (only difference: random seed)
	\item Sometimes SLS algorithm doesn’t even terminate at all: stagnation
\end{itemize}
If an SLS algorithm sometimes stagnates its mean runtime becomes \textbf{\red{infinity}}... Thus in practice, one often counts timeouts as some fixed large value $ X $. In either case however, summary statistics, such as mean run time or median run time, don't tell the whole story (e.g.: would penalize an algorithm that often finds a solution quickly but sometime stagnates). \\ \\
Consequently the \textbf{key idea} behind SLS is really combining greedily improving moves with randomization. This means that as well as improving steps we can allow a "small probability" of:
\begin{itemize}
	\item Random steps: move to random neighbor
	\item Random restarts: reassign random values to all variables.
\end{itemize}
Then we always keep best solution found so far, and we stop when either a solution is found (in vanilla CSP, all constraints satisfied) or we run out of time (in which case we return best solution so far).





\newpage

\section*{Lecture 15}
\textbf{February 6th, 2020} \\
\url{https://www.cs.ubc.ca/~jordon/teaching/cpsc322/2019w2/lectures/lecture15.pdf}
	
\subsection*{SLS Variants: Tabu Lists}
This variant aims at reducing problematic behaviors, in particular returning to recently visited nodes and cycling. In this case we maintain a \textbf{\blu{tabu}} list with the last \blu{$ k $} visited nodes. We then keep away from worlds that at in the \textit{tabu} list. 
	
	
\subsection*{SLS Variants: Stimulated Annealing}
\textbf{Key Idea:} Change the degree of randomness. \\ \\
In \textit{metallurgy} \blu{annealing} is a process where metals are heated and then \textit{slowly} cooled:
\begin{itemize}
	\item \textit{Analogy:} start with a high “temperature”: a high tendency to take random steps
	\item Over time, cool down: more likely to follow the scoring function
\end{itemize}
Temperature reduces over time, according to an annealing \blu{schedule}.

\subsubsection*{Stimulated Annealing: Algorithm}
Here is how it works, for maximizing $ h(n) $:
\begin{itemize}[label=$ \rightarrow $]
	\item You are in a node \blu{$ n $}. Pick a variable at random, and a new value at random. You generate \blu{$ n' $}.
	\item If it \textbf{\textsl{\gre{is}}} an improvement (i.e.: $ h(n') \geq h(n) $), then adopt it. 
	\item If it \textbf{\textsl{\red{isn't}}} an improvement, adopt it probabilistically, depending on the difference and a temperature parameter, $ T $:
	\begin{itemize}
		\item We move to $ n' $ with probability: $ e^{\frac{h(n')-h(n)}{T}} $
	\end{itemize}
\end{itemize}

\subsubsection*{Notes:}
\begin{itemize}
	\item If it isn't an improvement, adopt it probabilistically depending on the difference and a temperature parameter, $ T $. 
	\item Therefore having a \textbf{\red{higher}} temperature $ T $ means that the algorithm is \textbf{\blu{more}} likely to move to $ n' $ if it is “\textbf{\red{worse}}” than $ n $:
	\centerfig{0.75}{prob_T}
\end{itemize}

\subsubsection*{Properties of simulated annealing search}
One can prove: \\
If $ T $ \textbf{\textsl{decreases slowly enough}}, then stimulated annealing search will \textbf{find a global optimum with probability approaching 1}. \\ \\
Finding the ideal cooling schedule is unique to each class of problem:
\begin{itemize}
	\item Want to move off of local extrema but not global extrema
	\item Want to minimize computation time while taking enough time to ensure we reach a good minimum
\end{itemize}

\subsection*{SLS Variants: Population Based SLS}
Often we have more memory than the one required for current node (+ best so far + tabu list). \\ \\
\textbf{Key Idea:} maintain a population of $ k $ individuals:
\begin{itemize}
	\item At every stage, update your population.
	\item Whenever one individual is a solution, report it.
\end{itemize}
\textbf{Simplest strategy: Parallel Search}
\begin{itemize}
	\item All searches are independent
	\item No information shared
	\red{\item Essentially running $ k $ random restarts in parallel rather than in sequence}
	\item But we can take this idea...
\end{itemize}

\subsubsection*{Population Based SLS: Beam Search}
This is a \textbf{non stochastic} method. \begin{itemize}[label=$ \rightarrow $]
	\item It works like parallel search, with $ k $ individuals, but you choose the $ k $ best out of all of the neighbors.
	\item Useful information is passed among the $ k $ parallel search thread:
	\centerfig{0.9}{k_para_search}
	\item \textbf{Troublesome case:} If one individual generates several good neighbors, and the other $ k-1 $ individuals all generate bad successors, \red{then the next generation will consist of very similar individuals}...
\end{itemize}
\subsubsection*{Population Based SLS: Stochastic Beam Search}
\textbf{Non-stochastic} beam search may suffer from lack of diversity among the $ k $ individual (just a more expensive hill climbing). \textbf{Stochastic version} alleviates this problem:
\begin{itemize}[label=$\rightarrow$]
	\item Selects the $ k $ individuals at random (from neighbors $ n_1 $ to $ n_m $)
	\item But probability of selection proportional to their value (according to scoring function $ h(n) $)
\end{itemize}
Consequently, the advantages of using stochastic beam search is that it \textbf{maintains diversity} in the population. The \textbf{biological metaphor} would be (\textit{asexual reproduction}):
\begin{itemize}
	\item each individual generates “\blu{mutated}” copies of itself (its neighbors)
	\item The \blu{scoring function value} reflects \blu{the fitness} of the individual
	\item the higher the fitness the more likely the individual will survive (i.e., the neighbor will be in the next generation)
\end{itemize}

\subsection*{Population Based SLS: Genetic Algorithms}

\end{document}